2025-09-02 17:47:16,237 - INFO - Args: Namespace(num_seeds=8, seeds=[0, 1, 2, 3, 4, 5, 6, 7], sequence_length=5, num_sequences=2, student_dims=[150, 175, 200, 225, 250, 275], eps_train=1e-05, w_that_minimizes_loss=False, w2_that_minimizes_loss=False, gnc=True, gnc_num_samples=100000000, gnc_batch_size=100000, gd=True, gd_lr=0.001, gd_epochs=10000, gd_init_scale=0.01, gd_optimizer='adam', gd_scheduler=None, gd_scheduler_params='{}', exp_gamma=None, step_size=None, step_gamma=None, cosine_eta_min=None, gd_init_type='regular', config=None, results_dir=PosixPath('test_results/results'), figures_dir=PosixPath('test_results/figures'), checkpoint_dir=PosixPath('test_results/checkpoints'), checkpoint_interval=3600, resume_from_checkpoint=False, log_dir=PosixPath('test_results/logs'), max_gpus=4, log_file=PosixPath('test_results/logs/logs_20250902_174716.log'))
2025-09-02 17:47:16,239 - INFO - Using custom seeds: [0, 1, 2, 3, 4, 5, 6, 7]
2025-09-02 17:47:16,445 - INFO - Using GPUs: [0, 1, 2, 3]
2025-09-02 17:47:16,445 - INFO - Starting 4 processes on 4 GPUs
2025-09-02 17:47:21,826 - INFO - Process 2 started on GPU 2, processing seeds [4, 5]
2025-09-02 17:47:21,846 - INFO - Process 3 started on GPU 3, processing seeds [6, 7]
2025-09-02 17:47:21,846 - INFO - Process 1 started on GPU 1, processing seeds [2, 3]
2025-09-02 17:47:21,904 - INFO - Process 0 started on GPU 0, processing seeds [0, 1]
2025-09-02 17:47:22,056 - INFO - for seed 4, alpha_teacher=tensor([0.3049], device='cuda:2'), generated 2 sequences: [tensor([-0.2938,  0.7819, -1.4731,  1.0391], device='cuda:2'), tensor([-0.4015,  0.8411, -1.4424, -0.1211], device='cuda:2')]
2025-09-02 17:47:22,057 - INFO - Process 2: Starting experiment - student_dim=150, seed=4
2025-09-02 17:47:22,082 - INFO - for seed 2, alpha_teacher=tensor([0.5022], device='cuda:1'), generated 2 sequences: [tensor([ 2.2669,  1.3477, -1.4438, -1.0484], device='cuda:1'), tensor([-0.1825,  1.7087,  0.1843, -0.6569], device='cuda:1')]
2025-09-02 17:47:22,082 - INFO - for seed 6, alpha_teacher=tensor([0.5433], device='cuda:3'), generated 2 sequences: [tensor([ 1.9899, -0.1324, -0.3380, -0.7933], device='cuda:3'), tensor([ 0.4373,  0.6238, -2.2041, -0.1950], device='cuda:3')]
2025-09-02 17:47:22,082 - INFO - Process 1: Starting experiment - student_dim=150, seed=2
2025-09-02 17:47:22,082 - INFO - Process 3: Starting experiment - student_dim=150, seed=6
2025-09-02 17:47:22,281 - INFO - for seed 0, alpha_teacher=tensor([0.4075], device='cuda:0'), generated 2 sequences: [tensor([ 0.1808, -0.5523,  0.9238, -0.7350], device='cuda:0'), tensor([ 2.5441, -0.7163, -0.4934,  0.1267], device='cuda:0')]
2025-09-02 17:47:22,281 - INFO - Process 0: Starting experiment - student_dim=150, seed=0
2025-09-02 17:52:06,060 - WARNING - No GNC sensing losses for student dimension 150 seed 0
2025-09-02 17:52:07,252 - ERROR - G&C failed for student_dim=150, seed=0: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
2025-09-02 17:52:07,261 - ERROR - Traceback (most recent call last):
  File "/home/fodl/noacaspi/ssm_generalize/main.py", line 120, in process_worker
    theoretical_loss, theoretical_asymptotic_loss, delta_l_infinity = gnc_theoretical_loss(alpha_teacher, w_sequences, student_dim, device)
                                                                      ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 356, in gnc_theoretical_loss
    return gnc_theoretical_loss_for_multiple_w(alpha_teacher, w_sequences, student_dim, device)
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 189, in gnc_theoretical_loss_for_multiple_w
    return _gnc_theoretical_loss_for_two_w(alpha_teacher, w_sequences, student_dim, device)
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 252, in _gnc_theoretical_loss_for_two_w
    delta_l_infinity = - 2 + alpha_teacher**2 - alpha_teacher**4 + torch.sum(alpha_teacher**(2 * torch.arange(3, sequence_length - 1))) - asymptotic_conditional_expectation
                                                                             ~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  File "/home/fodl/noacaspi/miniconda3/envs/ssm/lib/python3.13/site-packages/torch/_tensor.py", line 39, in wrapped
    return f(*args, **kwargs)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!

2025-09-02 17:52:07,262 - INFO - No scheduler or scheduler type 'None', using empty params
2025-09-02 17:52:07,262 - INFO - Calling train_gd with scheduler_params: {}
2025-09-02 17:52:13,114 - INFO - initial model: max A_j index: 59
2025-09-02 17:52:26,577 - WARNING - No GNC sensing losses for student dimension 150 seed 4
2025-09-02 17:52:26,719 - ERROR - G&C failed for student_dim=150, seed=4: Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu!
2025-09-02 17:52:26,724 - ERROR - Traceback (most recent call last):
  File "/home/fodl/noacaspi/ssm_generalize/main.py", line 120, in process_worker
    theoretical_loss, theoretical_asymptotic_loss, delta_l_infinity = gnc_theoretical_loss(alpha_teacher, w_sequences, student_dim, device)
                                                                      ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 356, in gnc_theoretical_loss
    return gnc_theoretical_loss_for_multiple_w(alpha_teacher, w_sequences, student_dim, device)
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 189, in gnc_theoretical_loss_for_multiple_w
    return _gnc_theoretical_loss_for_two_w(alpha_teacher, w_sequences, student_dim, device)
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 252, in _gnc_theoretical_loss_for_two_w
    delta_l_infinity = - 2 + alpha_teacher**2 - alpha_teacher**4 + torch.sum(alpha_teacher**(2 * torch.arange(3, sequence_length - 1))) - asymptotic_conditional_expectation
                                                                             ~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  File "/home/fodl/noacaspi/miniconda3/envs/ssm/lib/python3.13/site-packages/torch/_tensor.py", line 39, in wrapped
    return f(*args, **kwargs)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu!

2025-09-02 17:52:26,724 - INFO - No scheduler or scheduler type 'None', using empty params
2025-09-02 17:52:26,724 - INFO - Calling train_gd with scheduler_params: {}
2025-09-02 17:52:29,045 - INFO - initial model: max A_j index: 98
2025-09-02 17:52:46,601 - WARNING - No GNC sensing losses for student dimension 150 seed 6
2025-09-02 17:52:46,747 - ERROR - G&C failed for student_dim=150, seed=6: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu!
2025-09-02 17:52:46,751 - ERROR - Traceback (most recent call last):
  File "/home/fodl/noacaspi/ssm_generalize/main.py", line 120, in process_worker
    theoretical_loss, theoretical_asymptotic_loss, delta_l_infinity = gnc_theoretical_loss(alpha_teacher, w_sequences, student_dim, device)
                                                                      ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 356, in gnc_theoretical_loss
    return gnc_theoretical_loss_for_multiple_w(alpha_teacher, w_sequences, student_dim, device)
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 189, in gnc_theoretical_loss_for_multiple_w
    return _gnc_theoretical_loss_for_two_w(alpha_teacher, w_sequences, student_dim, device)
  File "/home/fodl/noacaspi/ssm_generalize/theoretical_loss.py", line 252, in _gnc_theoretical_loss_for_two_w
    delta_l_infinity = - 2 + alpha_teacher**2 - alpha_teacher**4 + torch.sum(alpha_teacher**(2 * torch.arange(3, sequence_length - 1))) - asymptotic_conditional_expectation
                                                                             ~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  File "/home/fodl/noacaspi/miniconda3/envs/ssm/lib/python3.13/site-packages/torch/_tensor.py", line 39, in wrapped
    return f(*args, **kwargs)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu!

2025-09-02 17:52:46,751 - INFO - No scheduler or scheduler type 'None', using empty params
2025-09-02 17:52:46,751 - INFO - Calling train_gd with scheduler_params: {}
2025-09-02 17:52:46,944 - INFO - final model: max A_j index: 59, max A_j value: 0.0720858946442604, alpha_teacher: tensor([0.4075], device='cuda:0')
2025-09-02 17:52:47,006 - INFO - largest 10 A_j values: tensor([0.0721, 0.0560, 0.0507, 0.0507, 0.0431, 0.0417, 0.0411, 0.0375, 0.0371,
        0.0363], device='cuda:0', grad_fn=<TopkBackward0>)
2025-09-02 17:52:47,007 - INFO - number of values below 0.01: 94
2025-09-02 17:52:47,007 - INFO - number of values between 0.01 and 0.1: 56
2025-09-02 17:52:47,007 - INFO - number of values between 0.1 and 0.3: 0
2025-09-02 17:52:47,007 - INFO - number of values larger than 0.3: 0
2025-09-02 17:52:47,007 - INFO - train loss is 2.037117674547062e-08
2025-09-02 17:52:47,007 - INFO - impulse response loss is 0.014339515939354897
2025-09-02 17:52:47,008 - INFO - Process 0: Completed experiment - student_dim=150, seed=0
2025-09-02 17:52:49,104 - INFO - initial model: max A_j index: 10
2025-09-02 17:53:08,761 - INFO - final model: max A_j index: 98, max A_j value: 0.06795264035463333, alpha_teacher: tensor([0.3049], device='cuda:2')
2025-09-02 17:53:08,825 - INFO - largest 10 A_j values: tensor([0.0680, 0.0654, 0.0608, 0.0575, 0.0506, 0.0450, 0.0431, 0.0423, 0.0395,
        0.0388], device='cuda:2', grad_fn=<TopkBackward0>)
2025-09-02 17:53:08,826 - INFO - number of values below 0.01: 100
2025-09-02 17:53:08,826 - INFO - number of values between 0.01 and 0.1: 50
2025-09-02 17:53:08,826 - INFO - number of values between 0.1 and 0.3: 0
2025-09-02 17:53:08,827 - INFO - number of values larger than 0.3: 0
2025-09-02 17:53:08,827 - INFO - train loss is 1.2763401446846956e-13
2025-09-02 17:53:08,827 - INFO - impulse response loss is 0.00701425364241004
2025-09-02 17:53:08,828 - INFO - Process 2: Completed experiment - student_dim=150, seed=4
2025-09-02 17:53:22,929 - INFO - final model: max A_j index: 10, max A_j value: 0.002965496387332678, alpha_teacher: tensor([0.5433], device='cuda:3')
2025-09-02 17:53:22,992 - INFO - largest 10 A_j values: tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,
        0.0030], device='cuda:3', grad_fn=<TopkBackward0>)
2025-09-02 17:53:22,993 - INFO - number of values below 0.01: 150
2025-09-02 17:53:22,993 - INFO - number of values between 0.01 and 0.1: 0
2025-09-02 17:53:22,993 - INFO - number of values between 0.1 and 0.3: 0
2025-09-02 17:53:22,994 - INFO - number of values larger than 0.3: 0
2025-09-02 17:53:22,994 - INFO - train loss is 0.010936738923192024
2025-09-02 17:53:22,994 - INFO - impulse response loss is 0.129276305437088
2025-09-02 17:53:22,995 - INFO - Process 3: Completed experiment - student_dim=150, seed=6
